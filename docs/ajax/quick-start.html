{
  "title": "Quick Start",
  "content": "<div data-section id=\"quick-start\">\n<h1 id=\"nodetools-quick-start\">NodeTools Quick Start</h1>\n\n<p><em>NodeTools</em> is a full <em>Node.JS</em> stack which includes a number of packages for organising, testing, documenting and typing packages with JSDoc. It's very small (10 new dirs in TOTAL) and contains tools for essential operation of a package house. Dependencies that it installs provide an up-to-date development environment for local JavaScript development. It was created by a <a href=\"https://www.artd.eco\">\n  professional Node.JS development company in London</a> to meet modern requirements for bespoke and agile <em>Node.JS</em> development process. This guide will show how to start using the stack. If you have any questions, please refer to the <a href=\"/nodetools/#getting-help\">Getting Help</a> section. Be sure to subscribe to updates via the web-push button on the left, or email newsletter to be notified of new features first.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='40' height='15'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/0.svg\"></noscript></a>\n</p>\n</div>\n\n<div data-section id=\"install-mnp\">\n<h2 id=\"install-mnp\">Install MNP</h2>\n\n<p>The best way to start using <em>NodeTools</em>, is via <a\n   title=\"Create Packages From GitHub Templates. My New Package is an installer of new packages via GitHub templates: create a template and add an automated script to CLI questions, update files, access GitHub API and spawn commands during generation.\" class=\"NPMBadge\" href=\"https://www.npmjs.com/package/mnp\">\n   <span class=\"a\"><em>MNP</em></span><span class=\"b\">1.1.0</span></a> (My New Package) &mdash; a <em>GitHub</em> template-based package bootstrapper that allows to generate new repositories from templates and fill in the preset information into them. <span class=\"tm\">mnp</span> has only 3 small dependencies and can be installed globally:</p>\n\n<pre id=\"c724c1\"><code class=\"shell hljs\">yarn add global mnp\nnpm i -g mnp</code></pre>\n\n<p>After it's first been installed on the system, it needs to be configured with a global settings file in the home directory. Such settings can then be updated for any other organisational directories, but in general most of the properties will stay the same. To begin the configuration process, navigate to the home dir via terminal (<span class=\"tm\">cd ~</span>) and call <span class=\"tm\">mnp --init</span>.</p>\n\n<p>But first, a personal <a href=\"https://github.com/settings/tokens\">access token</a> needs to be generated for <em>GitHub</em> that will allow to access <em>GitHub</em> API. The <span class=\"tm\">delete_repo</span> and <span class=\"tm\">repo</span> permissions are needed to create new repositories and delete them from the CLI.</p>\n\n<pre id=\"c414d\"><code class=\"bash hljs\">GitHub access token: -new-access-token- #¬†generated token\nGitHub organisation: nodetools # either organisation or user login\nnpm scope: nodetools # optional scope for packages\nDefault Template: [mnpjs/package] # default template in org/name format\nuser: [Anton] #¬†the name for package.json, read from git config\nemail: [anton@adc.sh] #¬†the email for package.json, read from git config\nWebsite (for readme): https://www.art-deco.github.io/nodetools #¬†link to website\nTrademark (for readme): NodeTools # name in footer\nLegal name (for license): Art Deco Code Limited # full business name\nPackage Manager (yarn/npm): [yarn] # which package manager</code></pre>\n\n<p>These settings will be stored in the <span class=\"tm\">~/.mnprc</span> file and read by <em>MNP</em> upon each execution.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='40' height='13'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/1.svg\"></noscript></a>\n</p>\n</div>\n\n<div data-section id=\"configure-org\">\n<h2 id=\"configure-org\">Configure Org</h2>\n\n<p>Packages should be organised by organisations, which can be created for free on <em>GitHub</em> in unlimited number. Using personal repositories is also possible, in which case the name of the organisation is assumed to be the username. We'll create a new org folder in the home dir, and navigate into it:</p>\n\n<pre id=\"c724c\"><code class=\"shell hljs\">mkdir cool-org\ncd cool-org</code></pre>\n\n<p>Here, we can run <span class=\"tm\">mnp --init</span> again to update the settings for that particular org, however all the standard settings will be filled in already from the ones we wrote to the home directory.</p>\n\n<pre id=\"c414d1\"><code class=\"bash hljs\">GitHub access token: [8cb0f088cba5929dcd2337f906a9d8eca81d6759] # keep token\nGitHub organisation: [nodetools] cool-org # update org\nnpm scope: [nodetools] cool-org # update scope\nDefault Template: [mnpjs/package] # keep default\nuser: [Anton] # keep\nemail: [anton@adc.sh] # keep\nWebsite (for readme): [https://www.art-deco.github.io/nodetools] https://cool-org.com\nTrademark (for readme): [NodeTools] Cool Org\nLegal name (for license): [Art Deco Code Limited] # keep\nPackage Manager (yarn/npm): [yarn] # keep</code></pre>\n\n<p>After doing this, another <span class=\"tm\">.mnprc</span> will be created in the <span class=\"tm\">cool-org</span> folder, and these settings will be used for projects created in that organisation.</p>\n\n<p>After <em>MNP</em> is configured, we can proceed to creating a new package.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='40' height='13'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/2.svg\"></noscript></a>\n</p>\n</div>\n\n\n\n<div data-section id=\"spawn-package\">\n<h2 id=\"spawn-package\">Spawn Package</h2>\n\n<p>To create new packages from the default advanced <em>NodeTools</em> package template, we'll simply call <span class=\"tm\">mnp</span> in the <span class=\"tm\">cool-org</span> directory. The package bootstrapper will ask us some questions, after which we'll have a new package folder ready for development.</p>\n\n<pre id=\"c414d2\"><code class=\"bash hljs\">Package name: example-package # enter package name\n# @artdeco/example-package\nDescription: An example package created with MNP.\nGenerating repository...\nStarring...\n‚≠êÔ∏è Created and starred a new repository\nhttps://github.com/artdecocode/example-package\nCloning into '/Users/zavr/cool-org/example-package'...\nWith binary [y/n]: [y]\nBuild or compile: [compile]\nChoose a license (e.g., agpl-3.0, apache-2.0, bsd-3-clause, gpl-3.0, mit, custom)\nSee full list at https://github.com/mnpjs/licenses\nLicense: [agpl-3.0]\nInit Github Wiki [y/n]: [y]\nHomepage: [https://github.com/artdecocode/example-package#readme]\nKeywords (e.g., artdecocode, example-package): example, mnp\nPlease go to https://github.com/artdecocode/example-package/wiki/_new\nto create the first page and press enter when done. (y/n): [y]\nCloning into '/Users/zavr/cool-org/example-package/wiki.git'...\nSettings topics...\nyarn install v1.13.0\n[1/4] üîç  Resolving packages...\n[2/4] üöö  Fetching packages...\n[3/4] üîó  Linking dependencies...\nwarning \" &gt; depack@1.0.1\" has unmet peer dependency \"google-closure-compiler-java@*\".\n[4/4] üî®  Building fresh packages...\n‚ú®  Done in 2.70s.\nInitialised package structure, pushing...\nCreated a new package: @artdeco/example-package.</code></pre>\n\n<p><span class=\"tm\">mnp example-package</span> could be called right away from the CLI to fill in the package name immediately. If there was an error during the process, the remote repo and local folder can be deleted by calling <span class=\"tm\">mnp example-package -d</span> command that will ask for confirmation before proceeding to remove the repository from <em>GitHub</em>.</p>\n\n<p><em>MNP</em> will also run the package manager init script (such as <span class=\"tm\">yarn</span> or <span class=\"tm\">npm i</span>) in the new project folder. If <strong>VSCode</strong> was installed on the system, with the <span class=\"tm2\">code</span> binary <a href=\"https://code.visualstudio.com/docs/setup/mac\">exported to shell</a>, it will be automatically opened. A new tag <span class=\"tm\">v0.0.0-pre</span> will be added to the git tree at this point.</p>\n\n<h3 id=\"google-closure-compiler-java\">Google Closure Compiler Java</h3>\n\n<p>The <span class=\"tm\">&gt; depack@1.1.0 has unmet peer dependency &quot;google-closure-compiler-java@*&quot;.</span> warning is shown because <em>Depack</em> relies on <strong>Closure Compiler</strong> which should be installed as a package in the home dir, rather than inside of each new package individually. Unfortunately, neither <span class=\"tm\">yarn</span> nor <span class=\"tm\">npm</span> look up for the presence of this dependency locally, despite the fact that Node will traverse all dirs up to root (<span class=\"tm\">/Users/user/org/package</span>, <span class=\"tm\">/Users/user/org</span>, <span class=\"tm\">/Users/user</span>, <span class=\"tm\">/Users</span> and <span class=\"tm\">/</span>) to find dependencies there. To skip installing a compiler into each new package, we simply install it in <span class=\"tm\">~</span>:</p>\n\n<pre id=\"c414d3\"><code class=\"bash hljs\">cd ~\nyarn init # simple init\nyarn add google-closure-compiler-java</code></pre>\n\n<p>The compiler is recommended as it's one of the coolest features of the <em>NodeTools</em> stack.</p>\n\n<hr />\n\n<p>So in less than a minute, we're ready to write code, document and test our new package. Let's discuss some questions asked by <em>MNP</em> further.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='28' height='9'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/3.svg\"></noscript></a>\n</p>\n</div>\n\n<div data-section id=\"binary\">\n<h2 id=\"binary\">Binary</h2>\n\n<p><em>MNP</em> asked us if we want to create a binary. Binaries are great for <em>DevOps</em> to write scripts in Node.JS. Any system that has Node installed will be able to run those binaries. Even if a library was created first without a binary, it can be added later manually (by bootstrapping a new package and copying <span class=\"tm\">src/bin</span> dir and scripts in <strong>package.json</strong> from there. <small>We're working on the <strong>patch</strong> functionality of <em>MNP</em> that would allow to do that automatically</small>).</p>\n\n<p>Packages created with binaries can be executed from the command line. The source code for executable logic is placed into the <span class=\"tm\">src/bin</span> folder and contains a number of files:</p>\n\n<h3 id=\"-binindexjs\">¬†bin/index.js</h3>\n\n<p>This is the entry file for the development purposes. It's not used when the package is published. It only calls the <em>√ÄLaMode</em> handler to transpile source files on the fly, allowing to rename <span class=\"tm\">imports</span> into <span class=\"tm\">require</span> calls. It is also used when testing the package.</p>\n\n<pre id=\"ccdbf\"><code class=\"javascript hljs\">#!/usr/bin/env node\nrequire('alamode')()\nrequire('./mnp')</code></pre>\n\n<p>Additionally, the <strong>package.json</strong> will contain a number of records in the <span class=\"tm\">&quot;bin&quot;</span> property:</p>\n\n<pre id=\"cb9de\"><code class=\"json hljs\">{\n  \"bin\": {\n    \"example-package\": \"compile/bin/example-package.js\",\n    \"example-package-dev\": \"src/bin/index.js\"\n  },\n  \"files\": [\n    \"...files\",\n    \"src/bin/index.js\"\n  ]\n}</code></pre>\n\n<p>These aliases can then be called from anywhere on the system, if the package was installed globally, or via <span class=\"tm2\">yarn example-package</span> in other local packages that installed the binary. The <strong>example-package-dev</strong> binary record is used to call the binary from the local filesystem after it's been linked with <span class=\"tm\">yarn link</span> command in the project folder. For example, you might want to go to another package folder, and execute binary from there using the <span class=\"tm\">example-package-dev</span> command that will run the binary source code. This eliminates the need to build/compile the binary after each change, during the local development process while testing code on other packages. The <span class=\"tm\">files</span> property will also include the pointer to the <span class=\"tm\">src/bin/index.js</span> otherwise NPM would throw an error when trying to install our package.</p>\n\n<h3 id=\"binexample-packagejs\">bin/example-package.js</h3>\n\n<p>This is the actual binary logic that will be executed. Commands can be separated by placing them into the <span class=\"tm\">commands</span> directory, and then importing them from this file. We'll need to import args and the usage library that have been optimised for the use with <em>Closure Compiler</em>.</p>\n\n<pre id=\"ccdbf1\"><code class=\"javascript hljs\">import { _help, _init, _output, _version,\n  _input, argsConfig } from './get-args'\nimport { reduceUsage } from 'argufy'\nimport usually from 'usually'\n\nif (_help) {\n  const usage = usually({\n    description: 'An example package created with MNP.',\n    example: 'example-package example.txt -o out.txt',\n    line: 'example-package input [-o output] [-ihv]',\n    usage: reduceUsage(argsConfig),\n  })\n  console.log(usage)\n  process.exit(0)\n} else if (_version) {\n  console.log(require('../../package.json').version)\n  process.exit(0)\n}</code></pre>\n\n<h3 id=\"get-argsjs\">get-args.js</h3>\n\n<p>The arguments are generated using the <span class=\"tm2\">argufy</span> package that has been specifically developed to be compatible with <em>Closure Compiler</em>. All flags that are passed to binary via the <span class=\"tm\">process.argv</span> property will be parsed and made available for export from this file. They are exported with <span class=\"tm\">_</span> (underscore) to avoid errors when passing variables around. The arguments are generated from the <span class=\"tm\">types/arguments.xml</span> file that describes possible flags and their types:</p>\n\n<pre id=\"c16f7\"><code class=\"xml hljs\">&lt;arguments&gt;\n  &lt;arg command name=\"input\"&gt;\n    The path to the input file.\n  &lt;/arg&gt;\n  &lt;arg name=\"output\" short=\"o\" default=\"-\"&gt;\n    Where to save the output. By default prints to stdout.\n  &lt;/arg&gt;\n  &lt;arg boolean name=\"init\" short=\"i\"&gt;\n    Initialise in the current folder.\n  &lt;/arg&gt;\n  &lt;arg boolean name=\"help\" short=\"h\"&gt;\n    Print the help information and exit.\n  &lt;/arg&gt;\n  &lt;arg boolean name=\"version\" short=\"v\"&gt;\n    Show the version's number and exit.\n  &lt;/arg&gt;\n&lt;/arguments&gt;</code></pre>\n\n<p>When a change is made to the file, the <span class=\"tm\">yarn args</span> command need to be run to update the <strong>get-args</strong> file automatically via <span class=\"tm2\">argufy</span>. Moreover, the <span class=\"tm\">reduceUsage</span> command is imported from <span class=\"tm2\">argufy</span> package also to generate help information that can be passed to <span class=\"tm2\">usually</span> package to display usage info to users with <span class=\"tm\">-h</span> option.</p>\n\n<p>Furthermore, it is possible to separate arguments by functionality by creating multiple <strong>arguments.xml</strong> files, like it's been done in <a href=\"https://github.com/artdecocode/expensive/tree/master/types/args\">Expensive</a> and <a href=\"https://github.com/artdecocode/logarithm/tree/master/types/args\">Logarithm</a> packages, however the template does not use this method. Refer to the source code of these 2 package to see how their arguments are implemented.</p>\n\n<p>When developing binary locally, it can be executed with the <span class=\"tm\">yarn dev -arg value -arg2</span> command. It will start a new Node process and run <strong>src/bin/index</strong> that will transpile the source-code on-the-fly. When it comes to compilation, the source code will either be transpiled into the <span class=\"tm\">build</span> folder using <em>√ÄLaMode</em> by simply renaming imports and exports, or into the <span class=\"tm\">compile</span> folder by executing <em>Closure Compiler</em> via <em>Depack</em>. By compiling a binary, its dependencies will all be merged into a single JS file, which will reduce the number of prod dependencies to 0. This is discussed next.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='28' height='9'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/4.svg\"></noscript></a>\n</p>\n</div>\n\n<div data-section id=\"using-compiler\">\n<h2 id=\"using-compiler\">Using Compiler</h2>\n\n<p>One of advantages for the stack is its ability to properly compile Node.JS packages with <em>Closure Compiler</em>. Initially, before such option was possible, we used to just transpile packages and put their source code into the <span class=\"tm\">build</span> folder. This is still possible, however it is now recommended to either compile the full package, or compile its dependencies into <em>StdLib</em> and build the source code. In both cases, the number of dependencies can be reduced to 0 which makes packages more appealing to users. This section shows how to use the compiler.</p>\n\n<h3 id=\"compilation\">Compilation</h3>\n\n<p>Next, <em>MNP</em> asked us if we wanted to build or compile packages. By default, the compilation method is chosen. Packages that will participate in compilation need to be adapted to the Compiler to avoid warnings, and have externs. An extern is a file that contains information about types in a program, such as its config. Without an extern, the advanced compilation is not possible, since the compiler renames property names on objects, so that our API contract would be broken. This means that we're not only feeding JS files to the compiler, but also maintaining a coherent structure for such process, and it's the purpose of <em>NodeTools</em> to provide tools for that.</p>\n\n<p>Moreover, the compiler removes <em>JSDoc</em> comments by default, but we want to annotate our API so that it's 100% usable for developers who will consume our package. Therefore, there are 2 types of types:</p>\n\n<ul>\n  <li>API types that describe methods in the package, found in <span class=\"tm\">types/api.xml</span>, and</li>\n  <li>Record/interfaces types that describe data structures, found in <span class=\"tm\">types/index.xml</span> file.</li>\n</ul>\n\n<p>The API contract is used to describe methods in the package using XML:</p>\n\n<pre id=\"c16f71\"><code class=\"xml hljs\">&lt;types namespace=\"_examplePackage\"&gt;\n  &lt;method name=\"examplePackage\" async return=\"string\"&gt;\n    &lt;arg type=\"!_examplePackage.Config\" name=\"config\"&gt;The config.&lt;/arg&gt;\n    An example package created with MNP.\n  &lt;/method&gt;\n&lt;/types&gt;</code></pre>\n\n<p>Using this data from the XML, we will then enrich our template (<span class=\"tm\">compile/template.js</span>) file that is then used to generate the entry point to the package (<span class=\"tm\">compile/index.js</span>) using the <span class=\"tm\">yarn template</span> command.</p>\n\n<pre id=\"ccdbf2\"><code class=\"javascript hljs\">const { _examplePackage } = require('./example-package')\n\n/**\n * @methodType {_examplePackage.examplePackage}\n */\nfunction examplePackage(config) {\n  return _examplePackage(config)\n}\n\nmodule.exports = examplePackage\n\n/* typal types/index.xml namespace */\n</code></pre>\n\n<p>The template requires the <strong>_examplePackage</strong> named export from the <span class=\"tm\">./example-package</span> file which is the actual compiled source code that includes all dependencies. In our example, it's quite simple:</p>\n\n<pre id=\"ccdbf3\"><code class=\"javascript hljs\">'use strict';\nconst c={black:30,red:31,green:32,yellow:33,blue:34,magenta:35,cyan:36,white:37,grey:90};module.exports={_examplePackage:async function(a={}){const {shouldRun:d=!0,text:b=\"\"}=a;if(!d)return\"\";a=(a=c.yellow)?`\\x1b[${a}m${b}\\x1b[0m`:b;console.log(\"@artdeco/example-package called with %s\",a);return b}};\n\n//# sourceMappingURL=example-package.js.map</code></pre>\n\n<p>The entry point that we passed to the compiler was <span class=\"tm\">src/depack.js</span>.</p>\n\n<pre id=\"ccdbf4\"><code class=\"javascript hljs\">import '../types/externs'\nimport examplePackage from './'\n\nmodule.exports = {\n  '_examplePackage': examplePackage,\n}</code></pre>\n\n<p>As you can see, we imported our externs from types and an API method from the source code. Importing externs is required to preserve the property names of the config, otherwise anyone who tries to use our package will pass properties from the config, but the program will not do anything as they will be renamed into properties like <span class=\"tm\">.a</span>, <span class=\"tm\">.b</span>, <em>etc</em>. The <strong>src/depack.js</strong> file is only used by the compiler to create the <strong>compile/example-package.js</strong> source code that is then required by <strong>compile/index.js</strong> &mdash; the entry point to the package (<span class=\"tm\">{ &quot;main&quot;: &quot;compile/index.js&quot; }</span> in <strong>package.json</strong>). Our template then wraps the imported function with its own function, and annotates it with <span class=\"tm\">@methodType {_examplePackage.examplePackage}</span>. When we call <span class=\"tm2\">yarn template</span>, <em>Typal</em> will find our method type from types, and place the correct <em>JSDoc</em> into the final JS.</p>\n\n<pre id=\"ccdbf5\"><code class=\"javascript hljs\">const { _examplePackage } = require('./example-package')\n\n/**\n * An example package created with MNP.\n * @param {!_examplePackage.Config} config Options for the program.\n * @param {boolean} [config.shouldRun=true] A boolean option. Default `true`.\n * @param {string} [config.text] A text to return.\n * @return {Promise&lt;string&gt;}\n */\nfunction examplePackage(config) {\n  return _examplePackage(config)\n}\n\nmodule.exports = examplePackage\n\n/* typal types/index.xml namespace */\n/**\n * @typedef {_examplePackage.Config} Config `Ôº†record` Options for the program.\n * @typedef {Object} _examplePackage.Config `Ôº†record` Options for the program.\n * @prop {boolean} [shouldRun=true] A boolean option. Default `true`.\n * @prop {string} [text] A text to return.\n */\n</code></pre>\n\n<p>The config type is also added in the entry point so that it's accessible to the <em>VSCode</em> engine when the package is required, and we get perfect developer experience when consuming this package. Therefore, the purpose of the template file, is to wrap the source code exported by Closure into a developer-friendly function, which is then decordated with <em>JSDoc</em> during templating by <em>Typal</em>. This allows to move away from <em>TypeScript</em> to pure <em>JSDoc</em>, and maintain types from XML files instead of having to updated them in different places.</p>\n\n<p>This method of the API is also placed in the <span class=\"tm\">types/index.js</span> which is used for development purposes only.</p>\n\n<pre id=\"ccdbf6\"><code class=\"javascript hljs\">export {}\n\n/* typal types/api.xml namespace */\n/**\n * @typedef {_examplePackage.examplePackage} examplePackage An example package created with MNP.\n * @typedef {(config: !_examplePackage.Config) =&gt; string} _examplePackage.examplePackage An example package created with MNP.\n */\n\n/**\n * @typedef {import('..').Config} _examplePackage.Config\n */</code></pre>\n\n<p>In there, we call <span class=\"tm\">export {}</span> so that <em>VSCode</em> is able to export types from it. We then use the <span class=\"tm\">typal</span> marker so that the typedef for the method can be generated. Finally, we manually import the config from the package's entry. What is the purpose of this method type? It is so that we can use it in our source code for development purposes:</p>\n\n<pre id=\"ccdbf7\"><code class=\"javascript hljs\">// src/index.js\nimport { c } from 'erte'\n\n/**\n * @type {_examplePackage.examplePackage}\n */\nexport default async function examplePackage(config = {}) {\n  const {\n    shouldRun = true,\n    text = '',\n  } = config\n  if (!shouldRun) return ''\n  console.log('@artdeco/example-package called with %s', c(text, 'yellow'))\n  return text\n}\n\n/**\n * @suppress {nonStandardJsDocs}\n * @typedef {import('../types').examplePackage} _examplePackage.examplePackage\n */\n</code></pre>\n\n<p>See how the method is not annotated with JSDoc itself, but only its type is given. This allows us to receive access to the config type by importing the actual function type, and validate types during the compilation process. This point is quite important as it means that we don't annotate code in the source code itself, but in XML files which are used as the single source of truth to:</p>\n\n<ul>\n  <li>Enrich functions from templates with automatic <span class=\"tm\">@param</span> annotations;</li>\n  <li>for development to access auto-completions by importing methods' typedefs;</li>\n  <li>during the compilation for type checking.</li>\n</ul>\n\n<p>The <strong>@suppress</strong> comment is needed as <em>Closure Compiler</em> does not understand the <span class=\"tm\">import</span> directive in typedefs. Each new typedef import needs its own separate block with <strong>@suppress</strong> command.</p>\n\n<p>The types are placed in <span class=\"tm\">externs</span> that were imported by <strong>src/depack.js</strong>, so that the Compiler will see <span class=\"tm\">@type {_examplePackage.examplePackage}</span> annotation in source, and will be able to match it against the type from extern. Types from <strong>types/index.js</strong> or <strong>compile/index.js</strong> are NOT used in compilation. They are written in a <em>JSDoc</em> format not understood by <em>Closure</em>, but recognised by <em>VSCode</em> (such as arrow functions notation that provide better experience).</p>\n\n<pre id=\"ccdbf8\"><code class=\"javascript hljs\">/**\n * @fileoverview\n * @externs\n */\n\n/* typal types/index.xml externs */\n/** @const */\nvar _examplePackage = {}\n/**\n * Options for the program.\n * @record\n */\n_examplePackage.Config\n/**\n * A boolean option. Default `true`.\n * @type {boolean|undefined}\n */\n_examplePackage.Config.prototype.shouldRun\n/**\n * A text to return.\n * @type {string|undefined}\n */\n_examplePackage.Config.prototype.text\n\n/* typal types/api.xml externs */\n/**\n * An example package created with MNP.\n * @typedef {function(!_examplePackage.Config): !Promise&lt;string&gt;}\n */\n_examplePackage.examplePackage\n</code></pre>\n\n<p>The types for externs have to be in a different format to standard <em>VSCode</em> JSDoc, because Closure has got its own parser. <em>Typal</em> accounts for that and generates externs in the suitable format. The <span class=\"tm\">@fileoverview</span>/<span class=\"tm\">@externs</span> comments at the top are needed so that the externs file can be simply imported from the source code. Otherwise, it would have to be passed on to depack via the <span class=\"tm\">--externs types/externs.js</span> command, but it's more intuitive to just import them. On top of that, the <span class=\"tm\">exters</span> file is also published and a record in <span class=\"tm2\">package.json</span> points to its location:</p>\n\n<pre id=\"cb9de1\"><code class=\"json hljs\">{\n  \"files\": [\n    \"types/externs.js\"\n  ],\n  \"externs\": \"types/externs.js\"\n}</code></pre>\n\n<p>The <span class=\"tm\">externs</span> field is looked up by <em>Depack</em> when we incorporate packages in other packages. For example, when our <span class=\"tm\">example-package</span> is actually consumed by another software, its types need to be preserved for the compiler, therefore we also publish our externs to facilitate integration into other packages. This is the essence of the compilation process. You can read more documentation on the <a\n   title=\"Proper Node.JS Package Compiler (And Front-End Code Bundler) With Closure Compiler. Can create a single executable JS file and merge and optimise all dependencies.\" class=\"NPMBadge\" href=\"https://www.npmjs.com/package/depack\">\n   <span class=\"a\"><em>Depack</em></span><span class=\"b\">1.1.0</span></a> page and its <a href=\"https://github.com/dpck/depack/wiki\">wiki</a> that also outlines whether you can use modules compiled with <em>Babel</em> and <em>CommonJS</em> modules in the process, but for the best results, make sure that packages that are imported in compiled software, also follow <em>NodeTools</em> conventions, such as providing externs and proper Closure Compiler annotations.</p>\n\n<p>Finally, if it's required to preserve <span class=\"tm\">require</span> statement, it's possible to add a simple comment before the package name. If a named export is being required, its name should be put in quotes to prevent the renaming of the property like so:</p>\n\n<pre id=\"ccdbf9\"><code class=\"javascript hljs\">const { 'a': a } = require(/* dpck */'package')\n// could ^ use destructuring but there's a bug in\n// Jan 2020 version of the compiler, so:\nconst example = require(/* dpck */'package')\nconst a = example['a']\n\n// invoke\nconsole.log(a({ 'configItem': 'test' }))</code></pre>\n\n<p>Adding a comment in <span class=\"tm\">require</span> will exclude required file from static analysis and from being added to Closure's compilation stack as <span class=\"tm\">require()</span> will be treated as dynamic call, i.e. the dependency will be linked dynamically rather than statically. This is useful when dependencies have not been adapted for use with <em>Closure</em>, however in that case, when passing config properties, they also need to be quoted, otherwise the compiler will rename them.</p>\n\n<p>Overall, just remember that advanced compilation changes property names, therefore we need externs. This is also true for external data such as JSON data received from HTTP API requests. We need to either provide externs, or quote properties to prevent mangling.</p>\n\n<p>Above, we talked about compiling libraries so that they can be required by other packages. The script is called <strong>lib</strong> and can be run using <span class=\"tm\">yarn lib</span>. To compile a binary, we call <span class=\"tm\">yarn bin</span> that will generate an executable JS file, add a shebang to it, and set executable permissions on it.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='40' height='10'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/5.svg\"></noscript></a>\n</p>\n</div>\n\n\n<div data-section id=\"building-transpilation\">\n<h2 id=\"building-transpilation\">Building (Transpilation)</h2>\n\n<p>Instead of transpiling packages, it's possible to just build them, which means renaming imports and exports into require calls and <strong>module.export</strong> assignments. This is a simpler strategy but it's rarely used. The main time when we want to build packages, is for larger projects that also might include JSX components and more complex structures. For example, if we use <span class=\"tm\">__dirname</span> in source code a lot, this variable will be different when compiled, therefore we might want to avoid having to worry about paths being the same. Our transpiler is regex-based and simply looks for <span class=\"tm\">import .../ export ...</span> statements without building ASTs which is faster, but might be less reliable. Refer to <a\n   title=\"A Regex-Based Transpiler Of Source Code To Allow Writing Import And Export Statements And JSX With 0 Dependencies.\" class=\"NPMBadge\" href=\"https://www.npmjs.com/package/alamode\">\n   <span class=\"a\"><em>√ÄLaMode</em></span><span class=\"b\">3.3.1</span></a> documentation to find out about some edge cases when the transpiler might fail. If it happens, try rearranging exported functions' positions, or placing them in separate files.</p>\n\n<h3 id=\"-lamode-modules\">¬†√ÄLaMode Modules</h3>\n\n<p>Because of <em>Babel</em> and <em>TypeScript</em>, it's become a standard for transpiled packages to add the <span class=\"tm\">__esModule: true</span> export and export the default function in the <span class=\"tm\">.default</span> property of the <strong>module</strong> object. This is not the case with <span class=\"tm\">√ÄLaMode</span>, which simply assigns the default export to <strong>module</strong>, and assigns named exports as its properties. The <span class=\"tm\">__esModule</span> is not used at all:</p>\n\n<pre id=\"ccdbf10\"><code class=\"javascript hljs\">import def from 'package'\n// let def = require('package'); if (def &amp;&amp; def.__esModule) def = def.default\n\nexport default class Example {}\n// =&gt; module.exports = class Example {}\nexport const test = 'hello'\n// =&gt; module.exports.test = 'hello'</code></pre>\n\n<p>There's absolutely no change to code apart from imports so that it still looks nice. But because of the <span class=\"tm\">__esModule</span> flag, some packages transpiled with Babel/TypeScript will require the additional check when importing them. When we know that the imported packages can skip this check (if they were also made with <em>NodeTools</em>), we can add them to the <span class=\"tm\">alamodeModules</span> field in the <span class=\"tm\">.alamoderc.json</span> configuration file:</p>\n\n<pre id=\"cb9de2\"><code class=\"json hljs\">{\n  \"env\": {\n    \"build\": {\n      \"import\": {\n        \"alamodeModules\": [\"argufy\", \"indicatrix\",\n          \"usually\", \"erte\"]\n      }\n    }\n  }\n}</code></pre>\n\n<p>This will remove the check when transpiling those packages. We can also set the <span class=\"tm\">alamode</span> field to true on the actual package itself it its <strong>package.json</strong>, so that all other packages that consume it will known that it's an <em>√ÄLaMode</em> module that doesn't require the <span class=\"tm\">__esModule</span> check (same works for packages written in <em>CommonJS</em> natively without transpilation step).</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='40' height='10'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/6.svg\"></noscript></a>\n</p>\n</div>\n\n<div data-section id=\"stdlib\">\n<h2 id=\"stdlib\">StdLib</h2>\n\n<p>As discussed above, we might not want to compile packages every time. Examples of larger projects that don't compile code are <a href=\"https://github.com/artdecocode/documentary\">Documentary</a> and <a href=\"https://github.com/artdecocode/splendid\">Splendid</a>. Because these pieces of software are finished products in themselves, and will not be used as libraries for incorporation into other packages, they can be built without advanced compilation that would require annotating everything everywhere. But to avoid having lots of dependencies that come with them and just form a library for the software product, we can create an <span class=\"tm\">stdlib</span> file that will require all dependencies, and compile them. Then, the source code will be updated to require methods from the <span class=\"tm\">stdlib</span> instead of actual packages.</p>\n\n<pre id=\"ccdbf11\"><code class=\"javascript hljs\">// src/stdlib.js\nimport { c } from 'erte'\nimport argufy, { reduceUsage } from 'argufy'\nimport usually from 'usually'\nimport indicatrix from 'indicatrix'\n\nmodule.exports = {\n  'c': c,\n  'reduceUsage': reduceUsage,\n  'argufy': argufy,\n  'usually': usually,\n  'indicatrix': indicatrix,\n}</code></pre>\n\n<p>The package's standard library imports methods from dependencies, and exports them using <span class=\"tm\">module.export</span> assignment. The names of named and default imports must be consistent across source files together with <span class=\"tm\">stdlib.js</span> file. The <strong>stdlib</strong> job from <span class=\"tm2\">package.json</span> is then used to put their source code together and produce a singe JS file:</p>\n\n<pre id=\"cb9de3\"><code class=\"json hljs\">{\n  \"stdlib\": \"depack src/stdlib.js -o stdlib/index.js -a -c -p --source_map_include_content\",\n  \"b\": \"ALAMODE_ENV=build alamode src -o build -i stdlib.js -s\"\n}</code></pre>\n\n<p>The arguments used for complation are <span class=\"tm\">-a</span> for <em>advanced</em> mode, <span class=\"tm\">-c</span> to indicated we're compiling a Node.JS package rather than producing a web-bundle, which <em>Depack</em> is also capable of doing, and <span class=\"tm\">-p</span> means pretty code. Source map will also be generated and put in the same directory, so that when debugging, we'll see the source code (however we won't be able to hover over variable names as <em>VSCode</em> doesn't <a href=\"https://github.com/Microsoft/vscode/issues/12066\">map symbols</a>). The build command sets the <strong>ALAMODE_ENV</strong> environment variable to <span class=\"tm\">build</span> which is used by <span class=\"tm\">.alamoderc.json</span> file during the build stage:</p>\n\n<pre id=\"cb9de4\"><code class=\"json hljs\">{\n  \"env\": {\n    \"build\": {\n      \"import\": {\n        \"stdlib\": {\n          \"path\": \"stdlib\",\n          \"packages\": [\n            \"argufy\", \"indicatrix\",\n            \"usually\", \"erte\"\n          ]\n        }\n      }\n    }\n  }\n}</code></pre>\n\n<p>Such configuration tells the transpiler when running on the <strong>build</strong> environment to apply the <span class=\"tm\">stdlib</span> config, such as that the location of the <span class=\"tm\">stdlib</span> is pointing to the <span class=\"tm2\">stdlib</span> dir, while 4 dependencies are being renamed. Each new dependency that is added to the <em>StdLib</em> also needs to be specified in the <strong>packages</strong> field otherwise it won't be transpiled. When building the package with the <span class=\"tm2\">yarn b</span> command (short for <span class=\"tm\">build</span>), the transpiler will rename symbols to require methods from <span class=\"tm\">stdlib</span>. This is why the names must be consistent.</p>\n\n<pre id=\"ccdbf12\"><code class=\"javascript hljs\">const { reduceUsage } = require('../../stdlib');\nconst { usually } = require('../../stdlib');\nconst { c } = require('../../stdlib');\nconst { indicatrix } = require('../../../stdlib');</code></pre>\n\n<p>This strategy is convenient for merging all dependencies suitable for compilation into a single JS file, which is used in a big piece of software. However, this is not recommended usage for libraries that can be compiled into other packages, as it does not allow to make sure that the library's own source won't produce any compiler warnings and errors during compilation.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='53' height='12'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/7.svg\"></noscript></a>\n</p>\n</div>\n\n\n<div data-section id=\"automation-of-documentation\">\n<h2 id=\"automation-of-documentation\">Automation of Documentation</h2>\n\n<p>The core value of <em>NodeTools</em> is automation, especially when it comes to documentation. To be able to embed output of programs together with their source code automatically, without having to copy-paste them by hand, was the initial requirement for the documentation engine called <em>Documentary</em>. When types and JSX transpilation were added, it became possible to construct markdown tables for types and use custom JSX components also. The documentation engine is started with the <span class=\"tm\">-d</span> flag that produces a verbose logging output, otherwise it's not visible what <em>Documentary</em> is doing.</p>\n\n<p>Documentation is placed in the <span class=\"tm\">documentary</span> folder, where sections are split by files and folders. They are then compiled into the <span class=\"tm\">README.md</span> file that gets published to <em>GitHub</em> and NPM. There are 2 special cases for files in each folder: <span class=\"tm\">index.md</span> and <span class=\"tm\">footer.md</span> which will be compiled first and last in that folder. Other files are read using alpha-numerical order, e.g., <span class=\"tm\">1-example.md</span>, <span class=\"tm\">2-test.md</span> and so on. There are certain markers and components that can be used to invoke documentation features, including:</p>\n\n<ul>\n  <li><span class=\"tm2\">%NPM example-package%</span>: the NPM badge</li>\n  <li><span class=\"tm2\">%TOC%</span>: the table of contents</li>\n  <li><span class=\"tm2\">%EXAMPLE: example, ../src =&gt; @artdeco/example-package%</span>: the examples, with renaming of source imports</li>\n  <li><span class=\"tm2\">%FORK example%</span>: the output of programs</li>\n  <li><span class=\"tm2\">&lt;typedef method=&quot;examplePackage&quot;&gt;types/api.xml&lt;/typedef&gt;</span>: to generate API method headings</li>\n  <li><span class=\"tm2\">&lt;typedef&gt;types/index.xml&lt;/typedef&gt;</span>: to generate types' information (configs, interfaces)</li>\n</ul>\n\n<p>When forking programs, <em>Documentary</em> automatically invokes the √ÄLaMode transpiler so that the source code can be forked natively. In addition, cache will be maintained in the <span class=\"tm\">.documentary/cache</span> folder for forks, so that if a script and its dependency tree didn't get modified, the output is taken from cache to save valuable time. Fork marker can also be changed to a fork component (<span class=\"tm2\">&lt;fork&gt;</span>) that provides a way to pass environment variables. Additional information is available from the <a href=\"https://github.com/artdecocode/documentary/wiki/Forks\">Wiki page</a>.</p>\n\n<p>The power of examples lies in the ability to execute them from documentation, which provides an additional quality assurance mechanics. This means that we don't even have to write tests for simplest use-cases, as when the README is compiled, we'll be able to visually see if the program is working. It's great for making sure that functionality that we advertise actually works. Any time a change to the package is made, it will be reflected in the examples' output so that we know we didn't accidentally break the advertised API contract with new code. Although such regression testing cannot 100% substitute proper unit and integration tests with edge cases, it can help us make sure that the program remains correct through versions.</p>\n\n<h3 id=\"jsx-components\">JSX Components</h3>\n\n<p>Another cool feature is the ability to write our own components that could be invoked in documentation. The template used already has one component in the <span class=\"tm\">.documentary/index.jsx</span> file, that will construct a footer.</p>\n\n<pre id=\"ccdbf13\"><code class=\"javascript hljs\">/**\n * The footer for documentation.\n */\nexport const footer = () =&gt; {\n  const alt = 'idiocc'\n  const src = 'https://avatars1.githubusercontent.com/u/40834161?v=4&amp;s=100'\n  const href = 'https://www.artd.eco'\n  const org = 'Art Deco‚Ñ¢'\n  const year = new Date().getFullYear()\n  return [\n    (&lt;table&gt;\n      &lt;tr&gt;\n        &lt;td&gt;\n          &lt;img src={src} alt={alt} /&gt;\n        &lt;/td&gt;\n        &lt;td&gt;\n          ¬© &lt;a href={href}&gt;{org}&lt;/a&gt; {year}\n        &lt;/td&gt;\n      &lt;/tr&gt;\n    &lt;/table&gt;),\n  ]\n}</code></pre>\n\n<p>The avatar src and org names should automatically be updated with values that were specified in the MNP settings. This simple component will print a table with the picture of the organisation, its name, and year. This example can be used to create own components. Some more advanced examples include <em>Splendid</em> (static website compiler) component that is used to print how compiled HTML code looks like, by importing the function that generates HTML from the source code, and passing properties and children of the component to it. You can study it from <a href=\"https://github.com/artdecocode/splendid/blob/master/.documentary/index.jsx\">Splendid's repo</a>.</p>\n\n<p>By writing components for our complex software, we can avoid having to run a development server and copying and pasting generated example HTML, which is neither scalable nor reliable since our examples might break. By automating the process of documentation with custom components, we not only save a lot of time, but provide a robust mechanism to keep examples up-to-date and make sure that what we discuss in examples actually works. Therefore when documenting code, you might want to take 5 minutes to write a component that will format the output to your liking, that will in the end save hours of your time.</p>\n\n<p>The components receive properties parsed from HTML when used in markdown/html files as strings, numbers or booleans. There's also the <span class=\"tm\">documentary</span> property that can be accessed to disable pretty printing. <em>NodeTools</em> uses Preact 8 for its hyperdom functionality, but the components are rendered statically therefore they don't have state. Any component can return strings, JSX nodes or an array of the above (like fragments, but because Preact 8 doesn't support <span class=\"tm\">&lt;&gt;</span> fragments syntax, you can simply return an array). The following functions are <a href=\"https://github.com/artdecocode/documentary/blob/master/src/lib/components.js\">available</a> on the <span class=\"tm\">documentary</span> property:</p>\n\n<pre id=\"ccdbf14\"><code class=\"javascript hljs\">export const mycomponent = ({ documentary }) =&gt; {\n  // disable pretty printing (including new line breaks)\n  documentary.pretty(false)\n  // render inner html that might include new components\n  // 1st argument: doRender, is whether to render children\n  // 2nd argument: recursion, is whether components with the\n  //               same name will render again\n  documentary.renderAgain(true, false)\n  // prints error message with component name\n  documentary.error('message')\n  // if the component doesn't print anything,\n  // this method will return null and remove\n  // the line from the output\n  return documentary.removeLine(false)\n}</code></pre>\n\n<h3 id=\"typedefs\">Typedefs</h3>\n\n<p>The types are embedded with the <span class=\"tm\">typedef</span> component. A special case is when <span class=\"tm\">typedef</span> is called with <span class=\"tm\">method</span> property, which will print a heading with the description of an API method from types, for example:</p>\n\n<pre id=\"c16f72\"><code class=\"xml hljs\">&lt;typedef method=\"examplePackage\" [noArgTypesInToc]&gt;\n  types/api.xml\n&lt;/typedef&gt;</code></pre>\n\n<p>will produce a heading and description of the method, and include it in the table of contents (when the <span class=\"tm\">noArgTypesInToc</span> attribute is set, argument types won't appear in the TOC to make it more readable). The generated HTML will look like the following:</p>\n\n<pre id=\"c16f73\"><code class=\"xml hljs\">## &lt;code&gt;async &lt;ins&gt;examplePackage&lt;/ins&gt;(&lt;/code&gt;&lt;sub&gt;&lt;br/&gt;&amp;nbsp;&amp;nbsp;`config: !Config,`&lt;br/&gt;&lt;/sub&gt;&lt;code&gt;): &lt;i&gt;string&lt;/i&gt;&lt;/code&gt;\nAn example package created with MNP.\n\n - &lt;kbd&gt;&lt;strong&gt;config*&lt;/strong&gt;&lt;/kbd&gt; &lt;em&gt;&lt;code&gt;&lt;a href=\"#type-config\" title=\"Options for the program.\"&gt;!Config&lt;/a&gt;&lt;/code&gt;&lt;/em&gt;: The config.\n</code></pre>\n\n<p>Such headings can be customised, as discussed in <a href=\"https://github.com/artdecocode/documentary/wiki/Method-Titles\">Wiki</a>. The <a href=\"https://github.com/artdecocode/documentary/blob/master/src/components/method.jsx\">\n  default implementation</a> can be referred to also. When implementing custom methods' headings, the new component will replace the default one.</p>\n\n<p>To embed types for configs and interfaces, the standard typedef is used:</p>\n\n<pre id=\"c16f74\"><code class=\"xml hljs\">&lt;typedef [narrow] [name=\"TypeName\"]&gt;types/index.xml&lt;/typedef&gt;</code></pre>\n\n<p>By default, a markdown table is generated which is suitable for simple configs. When dealing with more complex types, that might include tripple-backticked source code, the <span class=\"tm\">narrow</span> property must be set which will generate a proper HTML table. A type name can be given to only embed a single type instead of all types in the XML file.</p>\n\n<h3 id=\"-namespaces\">¬†Namespaces</h3>\n\n<p>The types are written using namespaces, and the convention is to start the namespace with <span class=\"tm\">_</span> underscore. Namespaces allow to eliminate conflicts between types in packages. The <span class=\"tm\">doc</span> script is set to the following: <span class=\"tm2\">doc -o README.md -n _examplePackage -a -d</span>. The root namespace is thus set to <span class=\"tm\">_examplePackage</span> so that this namespace will not be shown in the documentation, but if the namespace is different, it will be printed.</p>\n\n<p>Namespaces are not compulsory and might be a new feature that you've not made use of before, however they help in the process greatly. For very simple packages, the namespace can be removed, but that would require to remove the <span class=\"tm\">-u</span> flag from <span class=\"tm\">typal</span> jobs, as well as removing the <span class=\"tm2\">namespace</span> arg from markers like <span class=\"tm\">/* typal types/index.xml namespace */</span> in typedefs.</p>\n\n<h3 id=\"annotations\">Annotations</h3>\n\n<p>When generating documentation and Wikis, all types that were referenced in the documentation will be accumulated and written in <span class=\"tm\">typedefs.json</span> file that is published with the package.</p>\n\n<pre id=\"ccdbf15\"><code class=\"javascript hljs\">{\n  \"_examplePackage.examplePackage\": {\n    \"link\": \"https://github.com/idiocc/example-package#async-examplepackageconfig-config-string\",\n    \"description\": \"An example package created with MNP.\"\n  },\n  \"_examplePackage.Config\": {\n    \"link\": \"https://github.com/idiocc/example-package#type-config\",\n    \"description\": \"Options for the program.\"\n  }\n}</code></pre>\n\n<p>Information from <span class=\"tm\">typedefs.json</span> file can be used when generating documentation of other packages, but they need to be embedded with <span class=\"tm\">&lt;include-typedefs&gt;example-package&lt;/include-typedefs&gt;</span> component. Documentary will then resolve the <span class=\"tm\">typedefs</span> field from the <span class=\"tm2\">package.json</span> of the referenced package (<span class=\"tm\">&quot;typedefs&quot;: &quot;typedefs.json&quot;</span>) and read the typedefs file. It will store the link and description of the type, and use this fields for links to external pages, and <span class=\"tm\">title</span> attributes for such links that show up on hover.</p>\n\n<h3 id=\"wikis\">Wikis</h3>\n\n<p>If you answered <span class=\"tm\">yes</span> to the question of whether to generate Wiki pages or not and then created a new Home Page for the new package, you'll be able to compile Wiki pages into the <span class=\"tm\">wiki.git</span> folder which is automatically installed as git submodule. To add a submodule is the most convenient way to maintain wiki pages in the same project. Your pages from the <span class=\"tm\">wiki</span> dir will be compiled into the <span class=\"tm\">wiki.git</span> folder, and you need to push them separately from the main repo.</p>\n\n<h3 id=\"watch-mode\">Watch Mode</h3>\n\n<p>The push process both for wikis and and README can be automated with <span class=\"tm\">-p [commit message]</span> command that will observe changes to the source documentation files, update them and the output in the git tree, and force push over the same commit with the same message that was specified under the <span class=\"tm\">-p</span> tag.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='53' height='12'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/8.svg\"></noscript></a>\n</p>\n</div>\n\n\n<div data-section id=\"context-testing\">\n<h2 id=\"context-testing\">Context Testing</h2>\n\n<p>A context is a class that can be used across test cases. Its main purpose is to separate testing utilities from test cases: by placing all code that is required to set up tests in a separate files, we can keep test suits clean of the noise, yet access the testing API easily and in the most developer-friendly way.</p>\n\n<pre id=\"ccdbf16\"><code class=\"javascript hljs\">// test/context/index.js\n/**\n * A testing context for the package.\n */\nexport default class Context {\n  async _init() {\n    LOG('init context')\n  }\n  /**\n   * Example method.\n   */\n  example() {\n    return 'OK'\n  }\n  /**\n   * A tagged template that returns the relative path to the fixture.\n   * @param {string} file\n   * @example\n   * fixture`input.txt` // -&gt; test/fixture/input.txt\n   */\n  fixture(file) {\n    const f = file.raw[0]\n    return join('test/fixture', f)\n  }\n  async _destroy() {\n    LOG('destroy context')\n  }\n  static get BIN() {\n    return BIN\n  }\n}</code></pre>\n\n<p>By providing JSDoc for documentation, the methods can be accessed via destructing in tests. Using context testing, we can always see what variables and functions are available to us from the testing context. It also allows to create as many files with test suites as we need without having to repeat ourselves when writing setting up and tearing down routines in <span class=\"tm\">before</span>, <span class=\"tm\">beforeEach</span>, <span class=\"tm\">after</span> and <span class=\"tm\">afterEach</span> blocks.</p>\n\n<p>\n  <img class=\"b-vk b-bk b-t\" alt=\"test context for example package\" data-io>\n  <noscript>\n    <img class=\"b-vk b-bk b-t\" alt=\"test context for example package\" src=\"/nodetools/pages/quick-start/images/context1.gif\">\n  </noscript>\n</p>\n\n<h3 id=\"-snapshots\">¬†Snapshots</h3>\n\n<p>Tests can simply return a string value which will be recorded in a snapshot in the <span class=\"tm\">test/snapshot</span> dir. Moreover, a readable stream can also be returned, and <em>Zoroaster</em> will collect all data returned from the stream and then compare it to the snapshot.</p>\n\n<pre id=\"ccdbf17\"><code class=\"javascript hljs\">import erte from '../../src'\n\n/** @type {Object.&lt;string, (c: Context)&gt;} */\nconst T = {\n  async 'returns a string in colour'({ string }) {\n    const res = erte(string, 'yellow')\n    return res\n  },\n}\n\nexport default T</code></pre>\n\n<p>If exporting a default test suite, we need to create a variable first and annotate it with type information, and export it as default only after, because <em>VS Code</em> will not be able to assign types to default exports.</p>\n\n<h3 id=\"mask-testing\">Mask Testing</h3>\n\n<p>A mask is a test case template that has fixed logic but whose test input and output data is read from a separate file called mask result file. Therefore, we can set up a test case once, but repeatedly run it for multiple inputs that are mapped against outputs, so that we only have to add new mappings in the result file, without having to repeat the JavaScript logic.</p>\n\n<pre id=\"ccdbf18\"><code class=\"javascript hljs\">// test/mask/default.js\nimport makeTestSuite from '@zoroaster/mask'\nimport Context from '../context'\nimport examplePackage from '../../src'\n\nexport default makeTestSuite('test/result/default', {\n  /**\n   * @param {Context} ctx\n   */\n  async getResults({ fixture }) {\n    const text = fixture`test.txt` + `\\n${this.input}`\n    const res = await examplePackage({\n      text,\n    })\n    return res\n  },\n  context: Context,\n})</code></pre>\n\n<p>We use the <span class=\"tm\">@zoroaster/mask</span> method to create a test suite which is then exported either as default or named export. <em>Zoroaster</em> context testing framework relies on √ÄLamode, when <span class=\"tm\">-a</span> flag is passed, so that like <em>Documentary</em>, it supports modules natively. The second argument to the <span class=\"tm\">makeTestSuite</span> function is the configuration object, and we need to implement the <span class=\"tm\">getResults</span> method (possibly asynchronous) that will run the test case and output the result. The result is that automatically compared against the declared one from the test result file. The input is read from the <span class=\"tm\">this.input</span> variable.</p>\n\n<p>The results are written in a separate file, in whatever most suitable file extension is, that supports syntax highlighting. <em>Zoroaster</em> supports <span class=\"tm\">.js</span> and <span class=\"tm\">.md</span> extensions from the box, where <span class=\"tm\">## test name</span> is used in markdown to indicate new tests, and <span class=\"tm\">// test name</span> in JS files. The expected output is added in the <span class=\"tm\">/* expected */</span> block. This can be controlled from the <span class=\"tm\">splitRe</span> option.</p>\n\n<pre id=\"c1953\"><code class=\"markdown hljs\">## returns the correct output\ntest\n\n/* expected */\ntest/fixture/test.txt\ntest\n/**/\n/* property */\n[\"additional\", \"property\"]\n/**/\n/* js-property */\n{ hello: 'world' }\n/**/</code></pre>\n\n<p>Contexts are also available to be used in masks. Access to the API is made possible via the arguments to the <span class=\"tm\">getResults</span> function, and any number of contexts can be passed. The <span class=\"tm\">makeTestSuite</span> method is quite robust and supports many options, such as:</p>\n\n<ul>\n  <li><span class=\"tm2\">getTransform</span>: allows to return a <em>Transform</em> stream to be ended with the input specified in the mask's result.</li>\n  <li><span class=\"tm2\">getReadable</span>: allows to return a <em>Readable</em> stream constructed with the input from the mask.</li>\n  <li><span class=\"tm2\">fork</span>: configuration for fork testing (see below).</li>\n  <li><span class=\"tm2\">mapActual</span>: is the <span class=\"tm\">getResults</span> returned a an object instead of a string, call this method to map which property of the object should be compared to the expected output.</li>\n  <li><span class=\"tm2\">assertResults</span>: additional assertions on results.</li>\n  <li><span class=\"tm2\">jsonProps</span>: properties that should be JSON-parsed (like above, <span class=\"tm\">/* property */</span> denotes a property which is exported in <span class=\"tm\">this.property</span> property of the mask).</li>\n  <li><span class=\"tm2\">js</span>: properties that should be JS-parsed.</li>\n  <li><span class=\"tm2\">splitRe</span>: regular expression to split the result files by. The default is <span class=\"tm\">/^\\/\\/ /gm</span> for results from all files, and <span class=\"tm\">/^## /gm</span> for results from <span class=\"tm\">.md</span> files.</li>\n  <li><span class=\"tm2\">propStartRe</span>: how to detect start of a property, e.g., in <span class=\"tm\">/‚Åé propName ‚Åé/</span>, the default <span class=\"tm\">/‚Åé</span> is used.</li>\n  <li><span class=\"tm2\">propEndRe</span>: how to detect end of a property, e.g, in <span class=\"tm\">/‚Åé propName ‚Åé/ some prop value /‚Åé‚Åé/</span>, the default <span class=\"tm\">/‚Åé‚Åé/</span> is used.</li>\n</ul>\n\n<h3 id=\"fork-testing\">Fork Testing</h3>\n\n<p><em>NodeTools</em> appreciates that powerful CLI applications can be written in Node.JS, however testing them has always been a chore. This is why <em>Zoroaster</em> is a powerful framework that provides a way to test forks automatically using mask testing. You can specify arguments to the program as inputs, and provide <span class=\"tm\">/* stdout */</span>, <span class=\"tm\">/* stderr */</span> and <span class=\"tm\">/* code */</span> properties of the mask result file (each one is optional but at least one is required). The fork will be spawned and outputs compared to the ones supplied in the mask result.</p>\n\n<pre id=\"c19531\"><code class=\"markdown hljs\">## runs the binary\ntest/fixture/test.txt\n\n/* stdout */\nmy-new-package called with a test file\n\na test file\n\n/**/\n\n/* stderr */\nFile test/fixture/test.txt successfully processed.\n/**/</code></pre>\n\n<p>You can do a lot of cool things like passing inputs to <strong>stdin</strong> by specifying the <span class=\"tm\">inputs</span> property:</p>\n\n<pre id=\"c19532\"><code class=\"markdown hljs\">## can register a domain\ncom\n\n/* inputs */\nApply coupon: n\nOK: y\n/**/\n\n/* stdout */\nApply coupon TLDEALZ01 (y/n)? [y] n\n\nPrice            8.88\nAdditional Cost  0.18\n-----            --------\nTotal            9.06 USD\n\nRegistering DOMAIN using:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ John Zoidberg, zoidberg@futurama.bz ‚îÇ\n‚îÇ  Planet Express                     ‚îÇ\n‚îÇ  57th Street                        ‚îÇ\n‚îÇ  New New York                       ‚îÇ\n‚îÇ  10019, US                          ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\nOK (y/n)? [n] y\nSuccessfully registered DOMAIN! Charged amount: $9.06.\n/**/</code></pre>\n\n<p><a href=\"https://github.com/artdecocode/expensive/blob/master/test/mask\">More examples</a> from <em>Expensive</em>.</p>\n\n<p>The fork property of the mask constructor can accept a single path to the fork, or additional advanced options known as <a href=\"https://github.com/contexttesting/fork#type-forkconfig\"><em>ForkConfig</em></a> that allow to specify CWD, enable logging and others.</p>\n\n<p>Of course, contexts can be used for fork-testing too. This is useful, for example, when a CLI program needs to interact with an external web service, so that we can mock an HTTP server that serves responses. The example below will start a server using a context, and pass the url as the first argument to the CLI.</p>\n\n<pre id=\"ccdbf19\"><code class=\"javascript hljs\">// mask\nimport clearr from 'clearr'\n\nexport default makeTestSuite('test/result/bin', {\n  context: Context,\n  fork: {\n    module: Context.BIN,\n    /**\n     * @param {string[]}\n     * @param {Context} context\n     */\n    async getArgs(args, { start }) {\n      const url = await start({\n        get: (ctx) =&gt; {\n          // assign response from the response\n          // property of the mask result.\n          ctx.body = this.response\n        },\n      })\n      return [url, ...args]\n    },\n    // use clearr package to remove\n    // loading indicator w/ \\r\n    preprocess: clearr,\n  },\n  jsonProps: ['response'],\n})</code></pre>\n\n<p>Or, we might want to make use of <span class=\"tm\">temp-context</span> to ensure that data is written or read from a file by the CLI. <a\n  href=\"https://github.com/artdecocode/typal/blob/f406f025b5025389e38e7ba2263e6e13d6acef7b/test/mask/bin.js#L5\">\n  The example</a> below will write data from the mask result into a file using the <span class=\"tm\">write</span> method of a temp context, and pass it as the first argument to the CLI whose job it is then to process this file in-place (the CLI updates the passed file). The spec in <span class=\"tm\">getResults</span> is used to create a snapshot of the updated file using the context. The snapshot is returned for assertion on the <span class=\"tm\">/* expected */</span> property. In other words, we add some JS in the mask result, write it to a temp file, use CLI to update this temp file, then return the snapshot of the temp folder that includes the temp file, and compare it to the expected value. By specifying the context as param to functions, we receive full <em>JSDoc</em> support.</p>\n\n<pre id=\"ccdbf20\"><code class=\"javascript hljs\">const TS = makeTestSuite('test/result/bin/default', {\n  context: TempContext,\n  fork: {\n    module: Context.BIN,\n    /**\n     * @param {string[]} args\n     * @param {TempContext} t\n     */\n    async getArgs(args, { write }) {\n      const p = await write('program.js', this.program)\n      return [p, ...args]\n    },\n  },\n  /**\n   * @param {TempContext} t\n   */\n  async getResults({ snapshot }) {\n    return snapshot()\n  },\n})</code></pre>\n\n<p><a href=\"https://github.com/artdecocode/logarithm/blob/master/test/mask\">More examples</a> from <em>Logarithm</em>.</p>\n\n<h3 id=\"persistent-contexts\">Persistent Contexts</h3>\n\n<p>In case when a certain long-running process (e.g., a connection to the database) needs to be initialised once per test suite, it's possible to assign it as a persistent context, rather than a one-use context.</p>\n\n<pre id=\"ccdbf21\"><code class=\"javascript hljs\">export const testSuite = {\n  persistentContext: class {\n    async _init() {\n      // initialised once per test suite\n      // ...\n      this.client = await client.connect('mongodb://localhost:27017')\n    }\n    async _destroy() {\n      await this.client.close()\n    }\n  },\n  context: [class {\n    _init() {\n      // initialised for each test\n      // ...\n    }\n    async startServer(mongo) {\n      return await start({ mongo })\n    }\n  }],\n  'test case'({ client }, { startServer }) {\n    const server = await startServer(client)\n    const res = await get(server.url)\n    equal(res.status, 200)\n  },\n}</code></pre>\n\n<p>Any number of contexts and persistent contexts can be passed, in an array, but persistent contexts will always be passed as arguments first. Read more about contexts on <a href=\"https://github.com/artdecocode/zoroaster\"><em>Zoroaster</em></a> documentation.</p>\n\n<h3 id=\"interactive\">Interactive</h3>\n\n<p>Whether for masks or snapshot testing, when <em>Zoroaster</em> is run in the interactive mode with the <span class=\"tm\">-i</span> flag, if the output was not what was expected, the testing framework will suggest that it should be updated (or new one recorded it there wasn't one before). This allows to quickly add expected outputs to masks.</p>\n\n\n<p>\n  <img class=\"b-vk b-bk b-t\" alt=\"interactivity during testing\" data-io>\n  <noscript>\n    <img class=\"b-vk b-bk b-t\" alt=\"interactivity during testing\" src=\"/nodetools/pages/quick-start/images/interactive.png\">\n  </noscript>\n</p>\n\n<h3 id=\"environments\">Environments</h3>\n\n<p>You might have noticed that there are additional test scripts: <span class=\"tm\">test-build</span> and <span class=\"tm\">test-compile</span> which set the <span class=\"tm2\">ALAMODE_ENV</span> variable. This variable controls the renaming of imports via the <span class=\"tm\">.alamoderc</span> file. It allows to run all test suites against compiled and build code, to make sure that not only source code is tested, but its derivatives prepared for publishing. When using <em>Closure Compiler</em>, it's pretty essential to run tests against the compiled version, because of the complexity of advanced compilation (e.g., it's possible we forgot to add a property to externs which then gets renamed so that the library does not work as expected).</p>\n\n<pre id=\"cb9de5\"><code class=\"json hljs\">{\n  \"env\": {\n    \"test-build\": {\n      \"import\": {\n        \"replacement\": {\n          \"from\": \"^((../)+)src\",\n          \"to\": \"$1build\"\n        }\n      }\n    },\n    \"test-compile\": {\n      \"import\": {\n        \"replacement\": {\n          \"from\": \"^((../)+)src$\",\n          \"to\": \"$1compile\"\n        }\n      }\n    }\n  }\n}</code></pre>\n\n<p>The renaming is done using simple regexes. When testing compiled folder, we can only test those files exported from the main <span class=\"tm\">src</span> file, i.e. from <span class=\"tm\">../src</span> but not <span class=\"tm\">../src/lib</span> because there's only one compiled file produced. Therefore the renaming is only possible with <span class=\"tm\">src$</span> regex that will rename imports exactly from <span class=\"tm\">src</span>. With the <strong>build</strong> environment this is not the case and we can unit test everything.</p>\n\n<p>When we test forks, the renaming doesn't work since we're hard-coding the location of the executable fork file, rather than importing it. Therefore, we need to manually control this path, which is done in Context:</p>\n\n<pre id=\"ccdbf22\"><code class=\"javascript hljs\">class Context {\n  static get BIN() {\n    return BIN\n  }\n}\nlet BIN = 'src/BIN'\nif (process.env.ALAMODE_ENV == 'test-build') {\n  console.log('Testing build bin...')\n  BIN = 'build/bin/mnp'\n} else if (process.env.ALAMODE_ENV == 'test-compile') {\n  console.log('Testing compile bin...')\n  BIN = 'compile/bin/mnp'\n}</code></pre>\n\n<p>By adding a single logging line with the information about the location of the fork, we can make sure that our set up is correct.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='41' height='13'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/9.svg\"></noscript></a>\n</p>\n</div>\n\n\n<div data-section id=\"debugging\">\n<h2 id=\"debugging\">Debugging</h2>\n\n<p>Debugging is an very important process and must be approached seriously. Professional software engineers always debug their programs with a debugger, rather than by leaving <strong>console.log</strong> statements as it saves a lot of time and allows to set through code line by line observing changes to variables.</p>\n\n<p>To start debugging, we need an entry point, i.e. a program that is using our written source code. There are 2 candidates for this: either tests, or examples. The best IDE for debugging is <em>VS Code</em> that allows to open file being debugged in write-mode, and make changes on-the-fly. Therefore, we've included the configuration necessary for debugging in <em>VS Code</em> called <strong>launch.json</strong> and it's found in the <span class=\"tm\">.vscode</span> folder. Don't be afraid to create as many records in the configs as you need, and commit them to remote repository. Configs are free and even if you and members of your team don't use same configs, it's better to still have them rather than having to create new ones each time because they were not committed to source control.</p>\n\n<pre id=\"cb9de6\"><code class=\"json hljs\">{\n  {\n    \"type\": \"node\",\n    \"request\": \"launch\",\n    \"name\": \"Launch Zoroaster\",\n    \"program\": \"${workspaceFolder}/node_modules/.bin/zoroaster\",\n    \"env\": {\n      // \"NODE_DEBUG\": \"my-new-package\",\n    },\n    \"console\": \"integratedTerminal\",\n    \"args\": [\n      \"test/spec\",\n      \"test/mask\",\n      \"-a\", \"-w\", \"-t\", \"9999999\"\n    ],\n    \"skipFiles\": [\n      \"&lt;node_internals&gt;/**/*.js\"\n    ]\n  },\n  {\n    \"type\": \"node\",\n    \"request\": \"launch\",\n    \"name\": \"Launch Example\",\n    \"program\": \"${workspaceFolder}/node_modules/.bin/alanode\",\n    \"console\": \"integratedTerminal\",\n    \"args\": [\n      \"example\"\n    ],\n    \"skipFiles\": [\n      \"&lt;node_internals&gt;/**/*.js\"\n    ]\n  }\n}\n</code></pre>\n\n<p>The configurations will launch either <strong>zoroaster</strong> or <strong>alanode</strong> binaries. By skipping node internals, we won't be jumping into Node's own source code, like <span class=\"tm\">fs.createReadStream('path')</span> or async hooks that are executed after async operations. <em>√ÄLaNode</em> is a simple binary that calls the √ÄLaMode require hook to enable transpilation of modules. You can also call it directly like <span class=\"tm\">yarn alanode example/src.js</span> to run examples or any scripts that you have.</p>\n\n<p>Using <em>VS Code</em> interface, we set breakpoints by clicking on the line where we want to stop, either in the source code or in tests/examples. It's also possible to simply write <strong>debugger</strong> statement in code manually. Then we launch the compiler (F5) which will pause at the breakpoint. We can then hover over variable names, and observe their values and call stack on the left. <em>Zoroaster</em> will be started in watch mode, so that every change will rerun tests (you'll need to unpause the debugger first if it paused on a breakpoint) without having to restart the debugger.</p>\n\n<p>\n  <img class=\"b-vk b-bk b-t\" alt=\"pausing at a breakpoint in zoroaster debugger\" data-io>\n  <noscript>\n    <img class=\"b-vk b-bk b-t\" alt=\"pausing at a breakpoint in zoroaster debugger\" src=\"/nodetools/pages/quick-start/images/debugging.gif\">\n  </noscript>\n</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='41' height='13'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/10.svg\"></noscript></a>\n</p>\n</div>\n\n<div data-section id=\"summary\">\n<h2 id=\"summary\">Summary</h2>\n\n<p><em>NodeTools</em> provides a holistic approach to pure Node.JS development and allows to maintain types without being locked in into <strong>TypeScript</strong>. Firstly, we can spawn packages quickly using <em>GitHub</em> templates via <em>MNP</em>. Then, by keeping types in XML files, we can generate externs for the compiler and typedefs for development purposes using <em>Typal</em> and also place types' tables and methods' headings in documentation. Examples and their output can also be placed into documentation which is put together by <em>Documentary</em>: this method provides an additional quality assurance control.</p>\n\n<p><em>Context-testing</em> is used for perfect developer experience during quality assurance that allows to reuse testing infrastructure across files easily via destructuring in test cases. Developers now can quickly glance at available testing API methods and access their <em>JSDoc</em> via the context. Destructured methods are already bound to instances of a context so they don't loose their scope like they would under normal circumstances:</p>\n\n<pre id=\"ccdbf23\"><code class=\"javascript hljs\">class Example {\n  constructor() {\n    this.hello = 'world'\n  }\n  method() {\n    return this.hello\n  }\n}\n\nconst e = new Example()\nconst { method } = e\nconst res = method() // undefined, not found\n\nexport const testSutie {\n  context: Example,\n  async'test case'({ method }) {\n    return method() // 'world', as method is bound\n  }\n}</code></pre>\n\n<p>Additionally, test contexts can be reused across packages, like <span class=\"tm\">temp-context</span> for system IO testing or <span class=\"tm\">@contexts/http</span> for HTTP server testing. These are just 2 examples of contexts that were published to be simply required in other packages that need such testing utilities, and any developer can make their own context that will improve productivity of the whole ecosystem. Moreover, <em>Zoroaster</em> testing framework is a simple yet advanced tool that introduces mask testing: a QA method that allows to set up a blueprint for test cases once (a mask), but feed multiple input/output pairs into it from a separate file (called mask result). Since mask results are placed in their own files of arbitrary extension, our dev experience is again improved by proper syntax highlighting. <em>Zoroaster</em> also has a powerful fork-testing built-in feature that makes testing forks a breeze. By using different environments, we are able to test not only the source code but the compiled or built code too.</p>\n\n<p>All of the above use <em>√ÄLaMode</em>, the simplest regex-based transpiler that only updates imports into common-js modules understood by Node.JS of lower versions. Now we don't need to install thousands of unknown dependencies and relinquish control of our <span class=\"tm\">node_modules</span> folder to have the essential stack required for productive Node development in 2020 with only 10 new folder in <span class=\"tm\">node_modules</span>.</p>\n\n<p>The introduction of the compiler into the Node.JS development methodology via <em>NodeTools</em> is the best feature of the stack that allows to statically link packages and reduce the number of dependencies to 0. However, that requires most consumed dependencies to be compiler-compatible, e.g., characterised by such features as the <strong>externs</strong> field in <span class=\"tm\">package.json</span>. <strong>Externs</strong> is a file that describes types for Closure Compiler in specially formatted <em>JSDoc</em> to prevent property names renaming during advanced compilation. <em>Depack</em> has provided <a href=\"https://github.com/externs/nodejs\">externs</a> for Node 8 built-in modules, such as <span class=\"tm\">fs.readFileSync</span>, <span class=\"tm\">stream.createReadable</span>, <em>etc</em> to enable type checking, however newer APIs might have been added to later versions (10, 12+). At the moment missing methods can be described manually in <span class=\"tm\">types/externs.js</span> files: simply add the missing property or method on the namespace, like so:</p>\n\n<pre id=\"ccdbf24\"><code class=\"javascript hljs\">/* typal types/index.xml externs */\n// generated externs\n\n/**\n * @param {string} path\n */\nfs.node10Method = function(path) {}</code></pre>\n\n<h3 id=\"-admin\">¬†Admin</h3>\n\n<p>If you want to make any changes to the package structure, you can simply fork the <span class=\"tm\">mnpjs/package</span> template, and update any part of it (such as eslint config) to your preference. Then simply push it to <em>GitHub</em> and specify it as the default template in the <span class=\"tm\">.mnprc</span> setting inside of the project or home directory. You can also study the <span class=\"tm\">mnp/index.js</span> script inside the template to find out how to create your own templates for <em>MNP</em>.</p>\n\n<p>The source code for all packages (except for templates which are MIT) is published under the AGPL license, however because the tools are used to facilitate the development process, and packages made with them don't link to them in any way (except if your package calls <em>√ÄLaMode</em> require hook from source at runtime which it won't unless you explicitly do that, like <em>Documentary</em> does for JSX support), you don't have to publish the source code of your packages according to AGPL. Only if you build new software upon those packages that this needs to be done, but we don't expect you too. Please file any issues in both target package and <a href=\"https://github.com/art-deco/nodetools\">NodeTools</a> repo itself.</p>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='29' height='9'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/11.svg\"></noscript></a>\n</p>\n</div>\n\n<div data-section id=\"examples\">\n<h2 id=\"examples\">Examples</h2>\n\n<p>There are a number of packages that were created using <em>NodeTools</em> stack. For references to actual packages you can explore the following:</p>\n\n<li><a href=\"https://github.com/idiocc/idio\">Idio web server</a>, the most advanced usage of <em>NodeTools</em> that generates and references lots of types across <span class=\"tm\">_idio</span> and <span class=\"tm\">_goa</span> namespace. Check out its template, and scripts used to generate typedefs. Have a look at all other middleware in the <a href=\"https://github.com/idiocc\">same namespace</a> that is compiled for individual standalone use, but is also adapted to be compiled into <em>Idio</em> itself.</li>\n<li><a href=\"https://github.com/idiocc/goa-router\">Goa Router</a>, a router which is defined using an interface in types, and uses a <span class=\"tm\">@constructor {_goa.Router}</span> template to generate a proxy to the actual class compiled with Closure.</li>\n<li><a href=\"https://github.com/wrote/temp-context#readme\">Temp Context</a>, a context used for testing IO operations using a temporary folder created in <span class=\"tm\">tests/temp</span> for each test case.</li>\n<li><a href=\"https://github.com/idiocc/http\">HTTP Context</a>, a context used for testing of HTTP servers in super-test style, that will create a listener for connections, and provide <span class=\"tm\">.get/post/put/etc</span> methods on the test object accessed via the context <a href=\"https://github.com/idiocc/idio/blob/master/test/spec/middleware/csrf-check.js#L6\">\n  testing API</a>.</li>\n<li><a href=\"https://github.com/artdecocode/typal/tree/master/test/mask\">Typal</a> has got a lot of mask testing setups that can provide some hints.</li>\n\n<p class=\"SectionBreak\">\n  <a title=\"Back To Top\" href=\"#top\">\n    <img alt=\"section break\"\n      src=\"data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='29' height='9'/%3E\" data-io>\n    <noscript><img alt=\"section break\" src=\"/nodetools/section-breaks/12.svg\"></noscript></a>\n</p>\n</div>\n\n<div data-section id=\"comments\">\n<h2 id=\"comments\">Comments</h2>\n\n<div id=\"comments-div\">Loading comments...</div>\n\n</div>",
  "file": "quick-start",
  "postAjax": "(function imgPostAjax() {\n  /* eslint-env browser */\n  window['IO']()\n  window['WEBP']()\n})()"
}